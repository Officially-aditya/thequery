# Appendix: Common Traps (Master List)

<details>
<summary><strong>Chapter 0: What AI Actually Is</strong></summary>

- Treating AI outputs as truth
- Assuming AI understands context
- "It works on my test set, ship it!"
- Anthropomorphizing the model
</details>

<details>
<summary><strong>Chapter 1: Python & Data</strong></summary>

- Not looking at your data
- Trusting data providers
- Ignoring missing data patterns
- Not versioning data
</details>

<details>
<summary><strong>Chapter 2: Math You Can't Escape</strong></summary>

- Memorizing formulas without understanding
- Getting stuck in math rabbit holes
- Skipping linear algebra
- Treating probability as just counting
</details>

<details>
<summary><strong>Chapter 3: Classical ML</strong></summary>

- Not using cross-validation
- Tuning hyperparameters on the test set
- Ignoring class imbalance
- Forgetting about feature scaling
</details>

<details>
<summary><strong>Chapter 4: Neural Networks</strong></summary>

- Not normalizing inputs
- Using sigmoid for hidden layers
- Not shuffling data
- Forgetting to set model to eval mode
- Not checking for NaNs
</details>

<details>
<summary><strong>Chapter 5: Transformers & LLMs</strong></summary>

- Trusting LLM outputs without verification
- Using LLMs for tasks requiring reasoning
- Ignoring cost
- Not handling edge cases
</details>

<details>
<summary><strong>Chapter 6: Modern AI Systems</strong></summary>

- Over-relying on LLMs
- Not versioning prompts
- Ignoring latency
- No fallback logic
</details>

<details>
<summary><strong>Chapter 7: Production AI</strong></summary>

- Deploying and forgetting
- Optimizing for accuracy alone
- Not planning for retraining
- Adding AI because it's trendy
</details>

---

